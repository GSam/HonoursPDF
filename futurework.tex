\chapter{Future work}\label{C:future}
The work done so far serves as definite proof of the concept and the techniques or approaches used to build the refactoring tool. To ensure that the tool serves practical use however, there is still significant work to be done. The scope of this additional work extends far beyond the time allocated and should serve as an adequate starting point for those looking to extend this work in the future. At this point the goal of this work is to address immediate shortcomings in the tool and to leave the more complicated refactoring and infrastructure changes for others (while providing useful commentary and insight). Lastly, with Rust being an open source project, there is the issue of upstreaming code and being mindful of the fact that the tool should follow as many coding conventions as possible.

\section{Multi-file projects}
At the moment, the refactoring tool only supports single file Rust programs. This is severe limitation in the ability of the tool to function practically since many Rust modules or crates are divided up into multiple files and organized in terms of directories for better code organization. 

Examining the current obstacles for providing this functionality, a separate approach must be taken from the current method using single files. This is brought about by multiple contributing factors. Firstly, rustc typically takes a single argument: the crate root, allowing the remaining files in the crate to be inferred. Due to the current structure of the compiler, these inferred files cannot be intercepted during the compilation process to facilitate the necessary compilation checks for the current renamings. 

The trivial solution to this problem is to modify the files on disk and to generate backup files before a renaming occurs. However, from a personal standpoint this is not a particularly satisfactory solution, especially with the current testing setup. The combination of modifying test files and having common test failures might be extremely cumbersome to deal with, but it may have to be tolerated. Alternatively, a temporary directory may be used to perform these compilation checks, however, ensuring the necessary dependencies are included could prove problematic. Ideally, modifications should be made to the compiler to allow a callback of some description during the parsing and interpretation of crates by the Rust compiler. Due to recent changes in the compiler, this approach appears quite feasible and should be achievable in the short term (1 to 2 weeks).

% Such a change does appear to be quite involved and changing a critical stage in the compiler is likely to present further issues in review and upstream of the code.

Another area of particular interest would be to investigate the overall effect of refactorings across multiple crates and how warnings should be presented when changes occur that might affect a public API. An investigation of Crates.io \cite{cratesio15}, the Rust package repository would likely yield interesting findings and in particular, identification of a description of the steps necessary to take when an API must change and how that should be dealt with from a community perspective. Looking at how the UNIX/Linux community deals with API or ABI changes in their open source software should also prove useful.

\section{Testing}
Going forward, the refactoring tool needs significantly more testing to ensure that the current set of refactorings are correct. In this scenario testing has an even more important role, it is to ensure that the existing refactorings are not broken with further changes to the tool. With the existing drastic changes to the approach required to progress to this stage, it appears likely that such changes are to be expected. Furthermore, the refactoring tool evolves independently of the Rust compiler and changes to the compiler are likely to affect the inevitable outcome of the refactoring tool. Already, a number of existing bugs have been found and reintroducing them by accident does not appear to be difficult with current limitations in the amount of testing and documentation available for some areas of the compiler. With unstable API it is unsurprising and so in this manner, expanding testing does not necessarily need to be confined to the refactoring tool. Tests should continue to be added for the remainder of the project to eliminate as many edge cases as possible.

With limited experience with Rust in general, using real world code to attempt refactorings would help test for more obscure corner cases which may have been overlooked. Crates.io \cite{cratesio15} should prove an invaluable resource for acquiring Rust code to perform such testing. Furthermore, initial analysis of the effiency of the tool can be produced and speculations as to the usefulness. The current testing programs are small and limited and by using real world code and by taking timing measurements, assessments can be made about how much faster the tool would be ideally. This should be possible after multi-file support is completed and should not pose any significant further issues, taking place during week 3 or 4 of Trimester 2.

\section{Future refactorings}
In terms of future refactorings, there are a number of next-step refactorings which should use most of the same infrastructure of the existing tool. For instance, struct fields or function arguments should function similarly to local variables and trait renaming should use most of the same conventions provided by concrete types like structs or enums. This is because of the output of save-analysis and the simplifications made in process of generating the csv output. A handful of these should be implemented relatively quickly, under a days work, however ensuring testing is adequate should take longer. As a whole, as many as possible should be implemented to provide a more comprehensive tool, however due to their simplicity they should not be the highest priority.

Renaming and modifying type aliases should also present interesting problems due to deviations from typical object-orientated languages, along with type parameters and associated types. Furthermore, as previously described, renaming types declared within some lexical scope or block introduce issues to do with path resolution that still need to be resolved. To do so requires determining which parts of the path are `private' to that scope and should not be used in the general case. The treatment of types in Rust definitely complicates matters, and this is already with the simplifications made from save-analysis.

In the context of Rust, there are a number of refactorings which would be more unique. Extraction of a method, as described by Fowler, presents a number of intricacies tied with lifetimes and the ownership system in Rust. Ensuring borrows are made correctly as well as dealing with move semantics if a constructor is within the extracted section of code present difficulties relatively specific to Rust refactoring. While other refactoring changes are semantics preserving, extraction of a method could introduce new lifetimes and verification of correctness may not be so trivial. Similarly, extraction and inlining of local variables also appears to provide adequate difficulties with the ownership system and should be able to provide further insight into approaching method extraction. Researching as much as possible the potential for code extraction should provide more depth to the analysis made by this project and should comprise the majority of the remaining time spent. Achieving some form of code extraction would be ideal, but regardless the findings made should also provide noteworthy material.

Converting functions to methods or vice versa is also a critical function that would be useful for the Rust community. Such a change is common with unstable API and within Rust, although released, there are a number of unstable API. To alleviate issues with changes, supporting these changes with a refactoring tool would be incredibly useful, even if it only used a structural search and replace. This would provide functionality similar to gofmt and go-fix as Go originally updated their API \cite{gofix11}. Making changes which break a sizable amount of user-code is unfavourable, however, it usually must be done at some point and haivng a tool to remedy the stress of such a change would be good for both the developers of Rust and the community.

\noindent
A non-comprehensive list of further refactorings that might be considered are:
\begin{itemize}
\item Inlining methods
\item Inlining modules
\item Creating modules
\item Adding or removing arguments to functions
\item Moving inherited to trait
\item Extracting trait
\item Changing types to type aliases
\end{itemize}

% List a number of refactorings which would be interesting in the context of Rust
% Comparing closures to other languages
% Extract a global
% Constructor to factory?
% Unknown the extent to which refactoring works in unsafe code blocks

\section{Additional compiler improvements}
% -Z save-analysis
Given the current architecture of the tool, there are a number of further improvements that could be made to the compiler to improve its efficacy and efficiency. Using -Z save-analysis provides another additional step before a refactoring can be made. Furthermore, it must be generated every time a refactoring is to be undergone. By providing a library and API with which this information can be queried using the existing compiler API, the need for CSV parsing and associated unrelated complexity disappears. The actual performance offset of having to run the compiler again to generate this information does not disappear however.  By running all the way through to analysis, this still takes a significant amount of time. 

%[reference to compiler stages from earlier section]

%  Compiler speed-up + Name resolution at the lowest level
Helping to address performance in the compiler itself in the general case should also help to improve performance of the refactoring tool. However, based on the current design of the tool and the need for multiple runs with modified source, the issue of performance would be better addressed by improvements to the name resolution module in the Rust compiler. In particular, providing name resolution for usages instead of just at the declaration level would turn O(N) runs of the compiler into O(1) runs by using name resolution multiple times in a single run. Fundamentally this requires heavy changes to the structure of the compiler and the nature of name resolution. As it currently is, not every node gets its individual node id in nested expressions and to resolve this requires significantly more memory usage or novel, significant and well-architected changes, well beyond the scope of this project.

% Macro hygiene with types
% Renaming within macros - seems like a big problem

Currently macros are completely ignored by the save-analysis report generated by the compiler. As it is, this appears to be a major shortcoming in the refactoring tool that has yet to be addressed. However, not a lot can be done at this point due to the general limitations regarding macros and how they are typically ignored when generating metadata from the compiler. Without being able to identify any spans associated with macros, it isn't possible to make the necessary code transformations. Implementing the necessary functionality is certainly non-trivial and likely requires much better domain knowledge than that which could be provided here.

\section{Miscellaneous}
% Refactoring practical...
A user-study or fielding comments on the tool would provide some interesting feedback. In order to provide usefulness, this is incredibly important part of assessing a tool. Furthermore production of a prototype GUI tool or Emacs plugin could increase the amount of users of the tool, or people interested in the tool. That could generate interest in further development and further research began by this project.

% Macro hygiene vs refactoring
The relationship between macro hygiene and refactoring is particularly novel, but from initial analysis, does not appear to provide any particular benefits. Further research into the relationship might provide some unique insights and a system which is able to incorporate both would be of significant academic interest, and interest to this author.

% Clang map reduce - Google scale of refactoring necessary. Analysis of speed in general.
Effiency of large-scale refactoring in general needs more attention. Although analysis of individual packages on a service like Crates.io provides some benefits, it would be curious to see how a tool functions on code bases which are much larger, in the order of hundreds of thousands of lines of code or larger. Although the expectations on this particular tool are not quite so high, understanding the general tradeoffs of provably correct refactorings and time taken and developer perception of this tradeoff is likely to produce fascinating observations. Looking at the Google-scale of refactoring, Google have set up a Clang map-reduce to perform refactoring on large codebases over a network of machines \cite{carruth2011clang}. Evidently the utility and associated confidence in such refactorings led them to spend the time to create such a framework, but determining when this happens in the general case provides provocative food-for-thought.

