\chapter{Design of the Implementation}\label{C:wd}

\section{Overall approach}
% Redeclarations made under the same scope
% Every approach seems incredibly intrusive.

% With API changing, one of the first to implement anything which interfaces in this particular manner.

%[Split into two chapters?]
% Why was it in Rust vs other languages? 
\subsection{Choice of language}
The choice of implementing the refactoring tool in Rust is for a number of reasons. Without a strong background in the language, performing even manual refactoring would likely be more difficult. The Rust compiler is a major component of the project and being able to modify the compiler and to understand the function of the compiler has been incredibly important. This is especially the case when documentation is not up to date and the level of support for some feature or API is unknown. It is also critical when there are bugs in the compiler that need to be fixed and extensions required to facilitate refactoring. The tool itself could also be used to test its own source code. Lastly, a number of API and interoperability problems would likely be avoided and so limiting compiler interactions to Rust code appears to be the best idea. 

\subsection{Standalone binary vs library}
While the tool is written in Rust, it also functions as a library and should allow for interoperability with any possible tool, GUI or otherwise. The choice of creating a library vs. a standalone tool or binary has created a number of arguments back and forth, but at the moment, the functionality remains provided by a library-type interface. There are reasons that this may not be ideal, for instance, the compiler driver API in Rust for calling the compiler functions primarily on disk. Doing so introduces a number of dependencies for the library and force specific configurations for setting up the library, ones which would be made simpler with a single tool and no requirement for genericity. Additionally, in order to preserve state over a number of compile runs or to provide better caching, the library may be better off abandoing statelessness and run as a general background program with a well defined API instead of a regular library. On the other hand, providing a library allows linking against arbitrary programs and expectations of a library ensure that the aim of providing interfaces to refactor code is fulfilled.

% Error propogation system in terms of nesting, expectations on thread serialization
% Throwing exceptions... no null types

\subsection{The general approach to refactoring}
The Scala Refactoring tool describes a general approach to refactoring which can serve as a guideline for what to provide and what goals should be achieved when designing a refactoring tool \cite{stocker2010scala}.
%[Taken from http://scala-refactoring.org/wp-content/uploads/scala-refactoring.pdf to transcribe]
\begin{enumerate}
\item provide a user interface so that a specific refactoring can be discovered and invoked from the IDE.
\item analyze the program under refactoring to find out whether the refactoring is applicable and further to determine the parameters and constraints for the refactoring.
\item transform the program tree from its original form into a new refactored form according to the refactoringâ€™s configuration.
\item turn this new form back into source code, keeping as much of the original formatting in place as possible and to generate code for new parts of the program.
\item present the result of the refactoring to the user, typically in the form of a patch, and apply it to the source code.
\end{enumerate}

%[Figure describe work flow of refactoring or structure of the library]

%Caching to provide multiple refactorings in a single run and to only run the save-analysis where necessary again?

\section{The different conflict types}\label{S:different}
Performing renaming without the necessary checks is not a particularly difficult task, and one which could be approached with straightforward text-replace. What should be considered when performing an accurate refactoring is the potential to change behaviour and cause conflicts. Fundamentally, there are three different conflict types that occur with lexically scoped items. The naming convention here is taken from the comments of the gorename tool \cite{gorename15}.

\subsection{Super-block conflict}
Super-block conflicts occur when a new name coincides with one declared in an outer enclosing block. In this situation, any references to the name in the outer block could be shadowed by the new name.

\begin{fig}[H]
\begin{verbatim}
              int A = 1;                         int A = 1;
              int B = 2;                         int B = 2;
              {                                  {
                  int A = 3;                         int B = 3;
                  print B; // 2                      print B; // 3
              }                                  }
\end{verbatim}
\caption{Super-block conflict: Renaming block local A to shadow outer B}
\label{Fig:super}
\end{fig}

\subsection{Sub-block conflict}
Sub-block conflicts occur when a new name coincides with one declared in an inner sub-block. In this situation, any references to the name in the outer block when changed to the new name might be shadowed by the existing declaration in the sub-block.

\begin{fig}[H]
\begin{verbatim}
              int B = 1;                         int A = 1;
              {                                  {
                  int A = 2;                         int A = 2;
                  print B; // 1                      print A; // 2
              }                                  }
\end{verbatim}
\caption{Sub-block conflict: Renaming outer B forces block local A to shadow outer A}
\label{Fig:sub}
\end{fig}

\subsection{Same-block conflict}
In other languages, this normally occurs with local variables which appear in the same scope. However, as described earlier, let bindings allow the redeclaration of variables under the same name in the same scope. In Rust, this allows mutability to be modified while retaining the original name and is generally considered good practice. While this conflict doesn't occur in Rust in the context of local variables, they still occur with global static variables, fields, and other constructs like methods and types.

\begin{fig}[H]
\begin{verbatim}
              int A = 1;                         int A = 1;
              int B = 2;                         int A = 2;
\end{verbatim}
\caption{Same-block conflict: Renaming B to conflict with A in the same scope}
\label{Fig:same}
\end{fig}

\section{Defining the entry point}
\subsection{Identification of affected nodes}
In order to map a variable, function or type to the corresponding AST node, the save-analysis output must be provided. With the csv output, a user need only to present a file line and column to determine the node id of the referenced element. Within the library, the csv is read every time this operation is required and will always perform a full scan of the file lines. While this could be avoided, there is still the fundamental issue of providing the save-analysis output as input to the tool, ensuring a full scan will always be necessary regardless. A binary search mechanism for code spans (or regions) could be particularly efficient for searching for a node, however this would need some mechanism for long running updating of a code map and furthermore it is unlikely that this operation would incur any significant penalties compared to those encountered with the validity checking of refactoring to be examined.

\subsection{Simple command line}
With the library, a simple command line tool has been provided to give a user interface for a refactoring to be identified and invoked. The command line tool takes any new names required for a refactoring and takes the original name and code location (typically a declaration) which may be denoted with row and column numbers in the form \textless{}name\textgreater{}:\textless{}row\textgreater{}:\textless{}col\textgreater{}. Row and column may be replaced with -1, as a wildcard, to intiate any refactoring valid for a matching name (where the expectation is that only one such name will be found). The tool also takes the operation that should be undergone (var, type or fn), the save-analysis file, the source file and with that, executes the refactoring, outputing the result to standard output.

\begin{verbatim}
simple.rs file:
fn main() {
    let a = 1;
    let b = a + 1;
}

% refactor var dxr-temp/unknown_crate.csv simple.rs  a:-1:-1 c
a -1 -1
NODE ID: 9
fn main() {
    let c = 1;
    let b = c + 1;
}
\end{verbatim}

The above describes a simple renaming of local variable `a' to `c'. The tool has identified the corresponding node in the AST as having id 9 and has successfully carried out the renaming. If the tool fails, like when it finds a conflict, a simple error message `CONFLICT' is displayed.

\section{Building renamings}
When performing a renaming, there are two main operations that need to be performed:
\begin{itemize}
\item Finding all accesses of a declaration
\item Finding the declaration of an acesss
\end{itemize}

All of this information should be found in the save-analysis data, however, it is completely static and simplified. In order to be able to perform these operations in the general case, the compiler has to be run again. For a refactoring to succeed, all names in a refactored program must bind to the same declaration as the original program \cite{schafer2010specification}. All original uses should be updated to bind to the renamed declaration and any other usages binding to a different declaration, remain binded to a different declaration.
 
%\subsection{Access construction}


%One way of performing renaming is to use access construction. This assumes that we have a procedure to `construct an access', which when given a position and declaration, will bind to that declaration at that position. To rename, you first compute the declarations for every usage. You rename the declaration and then go through every name and construct an access which will bind to the declaration it bound to originally, replacing the original name. Using the process of constructing accesses, new names may have additional qualification, but will still yield a program with the same binding structure.

\chapter{Specifics of the Implementation}\label{C:impl}

In this chapter, details of the design are elaborated with greater detail on the technical specifics and Rust specific context. Most of the difficulties in implementation arise from shortcomings in the compiler, but also due to specific design decisions in the compiler which led to exposure of Rust specific oddities. In Section \ref{S:building}, the facilities for providing verification of renames are explored. In Section \ref{S:changes}, an overview of the changes required, predominantly in the compiler, are described. In Section \ref{S:limit}, a brief overview of some known limitations.

\section{Building renames with rustc}\label{S:building}
\subsection{Name resolution for renaming}
Given a node id, a new name, the save-analysis file and the crate root file, a rename refactoring then has enough information to begin. Loading in the csv analysis, there are two separate pieces of information that need to be identified: the declaration and the references. Once they are ascertained, we run the compiler API to invoke the compiler. Using name resolution within the compiler, we can attempt to resolve the new name at the declaration site in the AST to ensure that it does not cause any conflicts. By doing so, this would avoid same-block conflicts and prevent all super-block conflicts. This forces usages binding to different declarations to remain binded to their different declaration. This also prevents a number of valid renamings where there is no eventual usage of the shadowed item. This issue should be addressed in Section \ref{S:limit}. This check does not address the issue of sub-block conflicts, however. In order to do so would require name resolution to resolve the new name at each of the reference sites in the AST to ensure that it does not resolve. In the ideal case, name resolution would run with both the declaration renamed and the usages renamed. At each renamed usage, name resolution would check that the binding was made only to the renamed declaration.

Unfortunately, limitations imposed by the structure of name resolution and the internal representation mean that this is not possible. In order to provide functionality for detecting the missing sub-block conflicts, recompilation of the entire crate with a single use renamed is necessary. Of course this provides significant overhead, however, hopefully name resolution can provide the required functionality in the future. Apart from compilation, there does not appear to be any straightforward way to checking if a name already exists in the context for a usage. The full name resolution approach is one adopted by gorename \cite{gorename15} and is much more efficient in general due to the fact that only one compiler run should be necessary to check every modification point. The choice of employing the full compilation approach for declarations would provide complexities in providing a valid constructions of expressions to test the presence of an existing name. A generic approach could not be used and so constructions of different forms for variables and variations of types and functions would be necessary -- which might not be compatible with simple ad-hoc replacement at the source code level.

\subsection{Compilation run}
Adopting the compilation approach, each reference is renamed to the new name one at a time and compiled to ensure that it fails. If a compilation succeeds, then a super-block or sub-block conflict would have occurred in this location and the refactoring must be halted. Care must be taken to ensure that the compilation fails due to a name resolution problem and not one which is due to other failures. If all the compilations fail correctly, the refactoring proceeds and performs all renamings of the occurrences of a variable/function/type.

\section{The changes to libresolve}\label{S:changes}
In order to provide the necessary capabilities of name resolution, a number of modifications had to be made to the libresolve package within the Rust compiler. Name resolution occurs by walking the AST and resolving as it goes. As it proceeds through the AST, it maintains a list of ribs which correspond to lexical scopes and the various declarations made within them. By doing this, names defined within scopes can be checked, however unfortunately this means that libresolve and the associated resolve\_path call required for resolving a new name in the form of a path is not stateless. The module is built with resolution of an entire crate in mind and so every time a path resolution is required, the entire AST must be walked to find a single node. Compared to compilation, the cost should still not be significant, but there is still the challenge of stopping the walker (as part of the Visitor pattern) in the middle of a traversal. 

\subsection{The lack of inheritance}
Had Rust implemented simple, single inheritance, creation of a walker to terminate at a given node would be quite trivial. An obvious alternative would be to single copy-paste the name resolution walker and modify the functionality as per necessary. Unfortunately, even if the changes were accepted upstream, this demanded heavy modification to a number of interfaces and duplication of further code which relied on the name resolution walker as the only possible type of name resolution walker. Basically it was never built for a generic implementation. Inheritance is a proposed addition to Rust, however, little progress has been made, and there are a number of outstanding issues as to how it would fit in with the existing type system.

The second attempted approach was to attempt delegation to simulate the use of inheritance. Wrapping the API of existing walker with a new walker is quite simple, however, reverting control back to the new walker is not so trivial as calls will normally just continue with the internal walker and not with the wrapped one. In some situations, refactoring of the code to force the walk\_X functions to occur at the end of each visit function will allow very little overall duplication of code, however if multiple walk\_X calls are made within a single function there is no simple solution without modification to the old walker. Even performing this modification causes difficulty due to Rust and the mandatory requirement of ownership. In order to simulate inheritance, one approach would be to have the existing walker hold a field which contained a reference to either itself (for the default behaviour) or the new walker (for the new behaviour). Unfortunately, an object with a reference to itself under normal circumstances is quite difficult and prevented by the compiler due to move semantics. The concept of one (modifying) reference to any object is broken severely with any cyclical or circular referencing. There are ways around this, otherwise Rust would suffer in flexibility, but most of them require planning ahead like the use of reference counting. The RC\textless{}X\textgreater{} type is a reference counted pointer and solves any problems with creating circular graphs, however to use them for name resolution likely required conversion of the entire library.

Accepting that reference counting would entail much more work, the last approach was to hand a callback to the resolver to invoke at every AST node. It functions generally for what is required but in terms of modifying without changes to original implementation, inheritance still appears to be the ideal approach (for the Visitor pattern).

\subsection{resolve\_path termination and the issue of panics}
Now with a callback, and identification of the correct node location, the question is: What to do now? Deeply nested in the AST tree, the callback cannot simply halt the walker and leave it in the correct state to query the local ribs for lexical scoping. It is possible to simply panic and the stack unwind can be caught, however, the unwind mechanism is not built for general message passing (and nesting these captures is not recommended). In particular, information that can be passed through the panic should be serializable and the implementation of the resolver is not compliant with that, requiring a number of changes.

The resolution itself could be executed in the callback, however, the resolver now owns the callback and therefore makes it impossible to pass the resolver through as an argument of the callback due to the ownership system preventing two simultaneous mutable borrows. Therefore, this is not feasible under the current structure.

The remaining solution is to simply flag the resolver as complete and detecting this flag, perform no additional processing. The no additional processing is absolutely crucial due to the presence of the local ribs which are normally popped off as the scopes are exited. This appeared to be the only remaining practical solution to the issue of stopping the walker.

\section{Known limitations}\label{S:limit}
\subsection{Forcing super-block conflicts}
With the current setup, there are cases where a super-block conflict which shadows nothing, or has no usages, will still be counted as a conflict. There are a few advantages of preventing redeclaration under the same name, one of which is that instead of checking every usage of every name, you only need to check the usages for the name that has been renamed. In the full compiler scenario, this is particularly bad and slow. The reason such checking is unnecessary is due to the fact that outsider usages suddenly binding to your new declaration is impossible -- the declaration is never shadowing anything.

\subsection{Macros}
Due to macros and the incomplete information supplied by save-analysis, it should probably be encouraged that conflicts should be raised as a precautionary measure whenever possible. This makes it so that forcing super-block conflicts unnecessarily might actually prevent conflicts with unseen macros. An additional run could identify issues with macros, however referring back to Opdyke's 7th constraint, the main issue is with sub-block or super-block conflicts which cannot be detected with any usual means and do not cause compilation errors. Pretending to handle macros is likely worse than not promising anything at all and an extra compilation run is bound to occur eventually. The following example highlights the behaviour shift with macros which you can see with println! as a macro:

\begin{verbatim}
simple.rs file:
fn main() {
    let a = 1;
    println!("{}", a);
}

% refactor var dxr-temp/unknown_crate.csv simple.rs  a:-1:-1 c
a -1 -1
NODE ID: 9
fn main() {
    let c = 1;
    println!("{}", a);
}
\end{verbatim}

%\subsection{Unsuccessful attempts at refactorings?}
%\subsubsection{Lessons learnt}